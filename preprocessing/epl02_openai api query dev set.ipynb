{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the OpenAI application programming interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command prompt window:\n",
    ">> pip install openai\n",
    "\n",
    "https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.14.2 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/Development Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to outline inclusion criteria for three categories: diabetes, precision medicine, and primary study. \n",
      "\n",
      "Please wait for me to prompt you on what to do based on these criteria.  \n",
      "Here are the inclusion criteria:  \n",
      "\n",
      "DIABETES: Do not exclude any type of diabetes or prediabetes. The presence of certain conditions or risk factors may not definitively confirm that the study is related to diabetes or prediabetes, unless there is a clear link to diabetes pathophysiology, diagnosis, or management. \n",
      "\n",
      "PRECISION MEDICINE: Precision medicine is an assessment of genetic or metabolic state to guide preventive and therapeutic decisions in humans. Exclude epidemiological studies using traditional biomarkers only, focusing on omics (genomics, metabolomics, proteomics, lipidomics etc.) or multi-omics studies. \n",
      "\n",
      "PRIMARY STUDY: All types of studies, other than meta-analysis and systematic reviews, were evaluated as primary studies. Although it may bias the studies towards counting contributions of large biorepositories, secondary analysis of previously collected datasets was also included since these generate novel insights into the pathophysiology of diabetes for source populations that these biorepositories sample from.  \n",
      "Based on the PMID, title, abstract, and MeSH terms below and the previously described inclusion criteria, identify using 'yes' or 'no' as categorizations if the article fulfills the criteria for precision medicine, diabetes, and primary study. \n",
      "\n",
      "PMID: 34735502\n",
      "\n",
      "Title: The association between triglyceride-glucose index, cardio-cerebrovascular diseases, and death in Korean adults: A retrospective study based on the NHIS-HEALS cohort \n",
      "\n",
      "Abstract: Background: The triglyceride-glucose (TyG) index is a reliable indicator of insulin resistance. We aimed to investigate the TyG index in relation to cardio-cerebrovascular diseases (CCVDs and mortality._x000D__x000D_\n",
      "_x000D__x000D_\n",
      "Methods: This retrospective study included 114,603 subjects. The TyG index was categorized into four quartiles by sex: Q1, <8.249 and <8.063; Q2, 8.249‒<8.614 and 8.063‒<8.403; Q3, 8.614‒< 8.998 and 8.403‒<8.752; and Q4, 8.998 and 8.752, in men and women, respectively. To calculate hazard ratios (HRs) and 95% confidence intervals (CIs) for the primary outcomes (CCVDs and all-cause mortality) and secondary outcomes (cardiovascular diseases [CVDs], cerebrovascular diseases [CbVDs], CCVD-related deaths, or all-cause deaths), Cox proportional hazards regression models were adopted._x000D__x000D_\n",
      "_x000D__x000D_\n",
      "Results: Compared to Q1, the HRs (95% CIs) for the primary outcomes of Q2, Q3, and Q4 were 1.062 (0.981‒1.150), 1.110 (1.024-1.204), and 1.151 (1.058-1.252) in men and 1.099 (0.986-1.226), 1.046 (0.938-1.166), and 1.063 (0.954-1.184) in women, respectively, after adjusted for age, smoking status, drinking status, physical activity, body mass index, systolic blood pressure, low-density lipoprotein cholesterol, economic status, and anti-hypertensive medications. Fully adjusted HRs (95% CIs) for CVDs of Q2, Q3, and Q4 were 1.114 (0.969-1.282), 1.185 (1.031-1.363), and 1.232 (1.068-1.422) in men and 1.238 (1.017-1.508), 1.183 (0.971-1.440), and 1.238 (1.018-1.505) in women, respectively. The adjusted HRs (95% CIs) for ischemic CbVDs of Q2, Q3, and Q4 were 1.005 (0.850-1.187), 1.225 (1.041-1.441), and 1.232 (1.039-1.460) in men and 1.040 (0.821-1.316), 1.226 (0.981-1.532), and 1.312 (1.054-1.634) in women, respectively, while the TyG index was negatively associated with hemorrhagic CbVDs in women but not in men. The TyG index was not significantly associated with CCVD-related death or all-cause death in either sex._x000D__x000D_\n",
      "_x000D__x000D_\n",
      "Conclusions: Elevated TyG index was positively associated with the primary outcomes (CCVDs and all-cause mortality) in men and predicted higher risk of CVDs and ischemic CbVDs in both sexes._x000D__x000D_\n",
      "  \n",
      "\n",
      "MeSH: Adult,Aged,Blood Glucose,Cardiovascular Diseases,Cause of Death,Cerebrovascular Disorders,Female,Humans,Male,Middle Aged,Regression Analysis,Republic of Korea,Retrospective Studies,Triglycerides  \n",
      "\n",
      "Organize your analysis of this abstract in a table, with the following columns: PMID, title, precision medicine, diabetes, primary study. Please provide evidence directly from the PMID, title, abstract, and MeSH terms to justify your classifications. \n",
      "Now identify the source population. The correct source population is based on the study participants' racial/ethnic background, regardless of geographic location, and refers to humans specifically. Exclude plants and therapeutics that may originate in the region and non-human animal models. The options are humans descending from Central Asia (CA), Central and Eastern Europe (CEE), East Asia (EA), Latin America & Caribbean (LAC), Middle East & North Africa (MENA), South East Asia & Pacific Islands (SEAP), South Asia (SA), Sub-Saharan Africa (SSA), the United States of America and Canada (NA), or Western Europe (WE). \n",
      "\n",
      "Add the classification of the source population to the table in a separate column. You may only use the abbreviation of the source populations provided. \n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)\n",
    "\n",
    "prompt_pmid = prompt_generator(34735502, base_prompts, excel_path, sheet_name='Sheet1')\n",
    "\n",
    "print(base_prompts[0])\n",
    "print(base_prompts[1])\n",
    "print(prompt_pmid)\n",
    "print(base_prompts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Your Batch File\n",
    "\n",
    "https://platform.openai.com/docs/guides/batch\n",
    "\n",
    ".jsonl file where each line contains the details of an individual request to the API\n",
    "\n",
    "Each request must include a custom_id value\n",
    "\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_excel(excel_path, sheet_name='Sheet1')['PMID'].tolist()\n",
    "\n",
    "json_list_scenario1 = []\n",
    "json_list_scenario2 = []\n",
    "json_list_scenario3 = []\n",
    "json_list_scenario4 = []\n",
    "\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    # print(pmid)\n",
    "    prompt_pmid = prompt_generator(pmid, base_prompts, excel_path, sheet_name='Sheet1')\n",
    "    dict_pmid_scenario1 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario2 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario3 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    dict_pmid_scenario4 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    json_list_scenario1.append(dict_pmid_scenario1)\n",
    "    \n",
    "    json_list_scenario2.append(dict_pmid_scenario2)\n",
    "\n",
    "    json_list_scenario3.append(dict_pmid_scenario3)\n",
    "\n",
    "    json_list_scenario4.append(dict_pmid_scenario4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 1.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario1:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 2.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario2:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 3.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario3:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 4.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario4:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uploading Your Batch Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_input_file_scenario1 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 1.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario2 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 2.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario3 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 3.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario4 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 4.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-4yxGZHXkBjBhHAo4erzx9M\n",
      "file-4yxGZHXkBjBhHAo4erzx9M\n",
      "file-3Ji8rCg5wPwwFf97WAnNaD\n",
      "file-U4wG7HfCmHdCFd9dvMJYmQ\n"
     ]
    }
   ],
   "source": [
    "batch_input_file_scenario1_id = batch_input_file_scenario1.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario1 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario1_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"development data for PMID query - scenario 1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario2_id = batch_input_file_scenario2.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario2 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario2_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"development data for PMID query - scenario 2\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario3_id = batch_input_file_scenario3.id\n",
    "print(batch_input_file_scenario3_id)\n",
    "batch_created_scenario3 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario3_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"development data for PMID query - scenario 3\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario4_id = batch_input_file_scenario4.id\n",
    "print(batch_input_file_scenario4_id)\n",
    "batch_created_scenario4 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario4_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"development data for PMID query - scenario 4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n Development Data\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_scenario1_id = '{batch_created_scenario1.id}'\\n\")\n",
    "    f.write(f\"batch_created_scenario2_id = '{batch_created_scenario2.id}'\\n\")\n",
    "    f.write(f\"batch_created_scenario3_id = '{batch_created_scenario3.id}'\\n\")\n",
    "    f.write(f\"batch_created_scenario4_id = '{batch_created_scenario4.id}'\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_scenario1_id = batch_created_scenario1.id\n",
    "batch_created_scenario2_id = batch_created_scenario2.id\n",
    "batch_created_scenario3_id = batch_created_scenario3.id\n",
    "batch_created_scenario4_id = batch_created_scenario4.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking the Status of a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: completed; Scenario 2: completed; Scenario 3:completed; Scenario 4:in_progress\n"
     ]
    }
   ],
   "source": [
    "# batch_created_id = 'batch_675d9dc3f25881909544964060c659c3'\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_status_scenario1 = client.batches.retrieve(batch_created_scenario1_id)\n",
    "\n",
    "batch_status_scenario2 = client.batches.retrieve(batch_created_scenario2_id)\n",
    "batch_status_scenario3 = client.batches.retrieve(batch_created_scenario3_id)\n",
    "\n",
    "batch_status_scenario4 = client.batches.retrieve(batch_created_scenario4_id)\n",
    "\n",
    "print(\"Scenario 1: \" + batch_status_scenario1.status + \"; Scenario 2: \" + batch_status_scenario2.status + \"; Scenario 3:\" + batch_status_scenario3.status + \"; Scenario 4:\" + batch_status_scenario4.status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_scenario1 = client.files.content(batch_status_scenario1.output_file_id)\n",
    "file_response_scenario2 = client.files.content(batch_status_scenario2.output_file_id)\n",
    "file_response_scenario3 = client.files.content(batch_status_scenario3.output_file_id)\n",
    "file_response_scenario4 = client.files.content(batch_status_scenario4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_59713/903094406.py:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 1_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_59713/903094406.py:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 2_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_59713/903094406.py:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 3_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_59713/903094406.py:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 4_results.csv', index=False)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results1 = format_gpt_output(file_response_scenario1)\n",
    "results2 = format_gpt_output(file_response_scenario2)\n",
    "results3 = format_gpt_output(file_response_scenario3)\n",
    "results4 = format_gpt_output(file_response_scenario4)\n",
    "\n",
    "\n",
    "\n",
    "results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 1_results.csv', index=False)\n",
    "results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 2_results.csv', index=False)\n",
    "results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 3_results.csv', index=False)\n",
    "results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Development Scenario 4_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>gpt_precision_medicine</th>\n",
       "      <th>gpt_diabetes</th>\n",
       "      <th>gpt_primary_study</th>\n",
       "      <th>gpt_source_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34735502</td>\n",
       "      <td>The association between triglyceride-glucose ...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369557</td>\n",
       "      <td>Targeted sequencing of candidate genes of dys...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20838400</td>\n",
       "      <td>Are endocannabinoid type 1 receptor gene (CNR...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18820969</td>\n",
       "      <td>Cellulose biosynthesis by the beta-proteobact...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677465</td>\n",
       "      <td>No PERV transmission during a clinical trial ...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>lac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "0  34735502   The association between triglyceride-glucose ...   \n",
       "1  31369557   Targeted sequencing of candidate genes of dys...   \n",
       "2  20838400   Are endocannabinoid type 1 receptor gene (CNR...   \n",
       "3  18820969   Cellulose biosynthesis by the beta-proteobact...   \n",
       "4  27677465   No PERV transmission during a clinical trial ...   \n",
       "\n",
       "  gpt_precision_medicine gpt_diabetes gpt_primary_study gpt_source_population  \n",
       "0                     no           no               yes                    ea  \n",
       "1                    yes           no               yes                    sa  \n",
       "2                    yes           no               yes                   cee  \n",
       "3                     no           no               yes                   n/a  \n",
       "4                     no          yes               yes                   lac  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
