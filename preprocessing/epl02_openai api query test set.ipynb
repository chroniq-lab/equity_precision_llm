{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the OpenAI application programming interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command prompt window:\n",
    ">> pip install openai\n",
    "\n",
    "https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kneed) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kneed) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/Aamna Datasets/Test Data 1.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to outline inclusion criteria for three categories: diabetes, precision medicine, and primary study. \n",
      "\n",
      "Please wait for me to prompt you on what to do based on these criteria.  \n",
      "Here are the inclusion criteria:  \n",
      "\n",
      "DIABETES: Do not exclude any type of diabetes or prediabetes. The presence of certain conditions or risk factors may not definitively confirm that the study is related to diabetes or prediabetes, unless there is a clear link to diabetes pathophysiology, diagnosis, or management. \n",
      "\n",
      "PRECISION MEDICINE: Precision medicine is an assessment of genetic or metabolic state to guide preventive and therapeutic decisions in humans. Exclude epidemiological studies using traditional biomarkers only, focusing on omics (genomics, metabolomics, proteomics, lipidomics etc.) or multi-omics studies. \n",
      "\n",
      "PRIMARY STUDY: All types of studies, other than meta-analysis and systematic reviews, were evaluated as primary studies. Although it may bias the studies towards counting contributions of large biorepositories, secondary analysis of previously collected datasets was also included since these generate novel insights into the pathophysiology of diabetes for source populations that these biorepositories sample from.  \n",
      "Based on the PMID, title, abstract, and MeSH terms below and the previously described inclusion criteria, identify using 'yes' or 'no' as categorizations if the article fulfills the criteria for precision medicine, diabetes, and primary study. \n",
      "\n",
      "PMID: 23680249\n",
      "\n",
      "Title: Pattern and predictors of dyslipidemia in patients with type 2 diabetes mellitus \n",
      "\n",
      "Abstract: Dyslipidemia is a major risk factor for macro-vascular complications in patients with type 2 diabetes mellitus (T2DM). Present study explored pattern and predictors of dyslipidemia in Bangladeshi T2DM patients. The cross-sectional study is conducted among 366 consecutive eligible T2DM patients aged >30 years, BIRDEM diabetic hospital, during July-to-December 2010. Physical examination, diabetic profile, lipid profile and serum createnine was performed. Adjusted odds ratio and confidence limit were generated through binary logistic regression. Most frequent form (59.3%) of dyslipidemia is low HDL. Duration of T2DM is significantly correlated with TC (P<0.05), HDL (P<0.05) and LDL (P<0.05) in both male and female. Glycemic control in terms of HbA1c >7% appeared as predictor of dyslipidemia (P<0.01). Duration T2DM is associated with increased risk of having higher TC (P<0.05), LDL (P<0.05) and lower HDL (P<0.01) and does not seem to affect triglyceride (P>0.05). T2DM with comorbid hypertension seems to predict hyper tri-glyceridemia and lower HDL. Both TC-HDL ratio and LDL-HDL ratio appeared as good predictor of all four parameters of dyslipidemia (P<0.01). The characteristic features of diabetic dyslipidemia are low HDL, high triglyceride and LDL cholesterol level. Low HDL level is the most frequent type of abnormality. Poor glycemic control, prolonged duration, coexisting hypertension predicts dyslipidemia in T2DM.Copyright Â© 2013 Diabetes India. Published by Elsevier Ltd. All rights reserved.  \n",
      "\n",
      "MeSH: Adult, Blood Glucose, Cross-Sectional Studies, Diabetes Mellitus, Type 2, Dyslipidemias, Female, Humans, Male, Middle Aged, Predictive Value of Tests, Risk Factors  \n",
      "\n",
      "Organize your analysis of this abstract in a table, with the following columns: PMID, title, precision medicine, diabetes, primary study. Please provide evidence directly from the PMID, title, abstract, and MeSH terms to justify your classifications. \n",
      "Now identify the source population. The correct source population is based on the study participants' racial/ethnic background, regardless of geographic location, and refers to humans specifically. Exclude plants and therapeutics that may originate in the region and non-human animal models. The options are humans descending from Central Asia (CA), Central and Eastern Europe (CEE), East Asia (EA), Latin America & Caribbean (LAC), Middle East & North Africa (MENA), South East Asia & Pacific Islands (SEAP), South Asia (SA), Sub-Saharan Africa (SSA), the United States of America and Canada (NA), or Western Europe (WE). \n",
      "\n",
      "Add the classification of the source population to the table in a separate column. You may only use the abbreviation of the source populations provided. \n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)\n",
    "\n",
    "prompt_pmid = prompt_generator(23680249, base_prompts, excel_path, sheet_name = 'Sheet1')\n",
    "\n",
    "\n",
    "print(base_prompts[0])\n",
    "print(base_prompts[1])\n",
    "print(prompt_pmid)\n",
    "print(base_prompts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Your Batch File\n",
    "\n",
    "https://platform.openai.com/docs/guides/batch\n",
    "\n",
    ".jsonl file where each line contains the details of an individual request to the API\n",
    "\n",
    "Each request must include a custom_id value\n",
    "\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_excel(excel_path, sheet_name='Sheet1')['PMID'].tolist()\n",
    "\n",
    "json_list_scenario4 = []\n",
    "\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    dict_pmid_scenario4 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 2000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    json_list_scenario4.append(dict_pmid_scenario4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON files saved successfully to OneDrive folder:\n",
      "/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM/llm training/Aamna Datasets/output_part1.json\n",
      "/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM/llm training/Aamna Datasets/output_part2.json\n"
     ]
    }
   ],
   "source": [
    "# other option i tried to bypass token limit ********\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_list_scenario4 = []\n",
    "\n",
    "# Generate JSON objects\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    dict_pmid_scenario4 = {\n",
    "        \"custom_id\": f\"{index}_{pmid}\", \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-2024-08-06\", \n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                {\"role\": \"user\", \"content\": base_prompts[3]}\n",
    "            ],\n",
    "            \"max_tokens\": 2000,\n",
    "            \"frequency_penalty\": -0.2,\n",
    "            \"top_p\": 0.8,\n",
    "            \"presence_penalty\": -0.3\n",
    "        }\n",
    "    }\n",
    "    json_list_scenario4.append(dict_pmid_scenario4)\n",
    "\n",
    "# Split the JSON data\n",
    "mid_index = len(json_list_scenario4) // 2\n",
    "part1 = json_list_scenario4[:mid_index]\n",
    "part2 = json_list_scenario4[mid_index:]\n",
    "\n",
    "# Define the OneDrive folder path\n",
    "onedrive_path = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM/llm training/Aamna Datasets\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(onedrive_path, exist_ok=True)\n",
    "\n",
    "# Save each part as separate JSON files in OneDrive\n",
    "file1_path = os.path.join(onedrive_path, \"output_part1.json\")\n",
    "file2_path = os.path.join(onedrive_path, \"output_part2.json\")\n",
    "\n",
    "with open(file1_path, \"w\") as f1:\n",
    "    json.dump(part1, f1, indent=4)\n",
    "\n",
    "with open(file2_path, \"w\") as f2:\n",
    "    json.dump(part2, f2, indent=4)\n",
    "\n",
    "print(f\"JSON files saved successfully to OneDrive folder:\\n{file1_path}\\n{file2_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_73338/1418965083.py:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open(path_equity_precision_llm_folder + '\\llm training\\Test 1 Scenario 4.jsonl', 'w') as outfile:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Test 1 Scenario 4.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario4:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uploading Your Batch Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_73338/901617401.py:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  file=open(path_equity_precision_llm_folder + '\\llm training\\Test 1 Scenario 4.jsonl', \"rb\"),\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_input_file_scenario4 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Test 1 Scenario 4.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-UdZ1AUr1LdQ3UQfQGikV5y\n"
     ]
    }
   ],
   "source": [
    "batch_input_file_scenario4_id = batch_input_file_scenario4.id\n",
    "print(batch_input_file_scenario4_id)\n",
    "batch_created_scenario4 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario4_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"test 1 data for PMID query - scenario 4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_scenario4_id = '{batch_created_scenario4.id}'\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_scenario4_id = batch_created_scenario4.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking the Status of a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4: failed\n"
     ]
    }
   ],
   "source": [
    "# batch_created_id = 'batch_675d9dc3f25881909544964060c659c3'\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "\n",
    "batch_status_scenario4 = client.batches.retrieve(batch_created_scenario4_id)\n",
    "\n",
    "print(\"Scenario 4: \" + batch_status_scenario4.status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_scenario4 = client.files.content(batch_status_scenario4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results4 = format_gpt_output(file_response_scenario4)\n",
    "\n",
    "results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Test 1 Scenario 4_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>gpt_precision_medicine</th>\n",
       "      <th>gpt_diabetes</th>\n",
       "      <th>gpt_primary_study</th>\n",
       "      <th>gpt_source_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22744164</td>\n",
       "      <td>Acculturation and glycemic control of Asian I...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15561964</td>\n",
       "      <td>Linkage analysis of diabetes status among hyp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28770629</td>\n",
       "      <td>Ipragliflozin, a sodium glucose co-transporte...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33764184</td>\n",
       "      <td>Gastrodin protects against high glucose-induc...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36155119</td>\n",
       "      <td>Curcumin supplementation reduces blood glucos...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>lac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "1  22744164   Acculturation and glycemic control of Asian I...   \n",
       "1  15561964   Linkage analysis of diabetes status among hyp...   \n",
       "1  28770629   Ipragliflozin, a sodium glucose co-transporte...   \n",
       "1  33764184   Gastrodin protects against high glucose-induc...   \n",
       "1  36155119   Curcumin supplementation reduces blood glucos...   \n",
       "\n",
       "  gpt_precision_medicine gpt_diabetes gpt_primary_study gpt_source_population  \n",
       "1                     no          yes               yes                    sa  \n",
       "1                    yes          yes               yes                    na  \n",
       "1                     no          yes               yes                    ea  \n",
       "1                    yes          yes               yes        not applicable  \n",
       "1                     no          yes               yes                   lac  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
