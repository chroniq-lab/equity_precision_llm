{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the OpenAI application programming interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command prompt window:\n",
    ">> pip install openai\n",
    "\n",
    "https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.14.2 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/epldat03_Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Your Batch File\n",
    "\n",
    "https://platform.openai.com/docs/guides/batch\n",
    "\n",
    ".jsonl file where each line contains the details of an individual request to the API\n",
    "\n",
    "Each request must include a custom_id value\n",
    "\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_excel(excel_path, sheet_name='Sheet1')['PMID'].tolist()\n",
    "\n",
    "json_list_test = []\n",
    "df = pd.read_excel(excel_path, sheet_name= \"Sheet1\")\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    prompt_pmid = prompt_generator_v2(pmid, base_prompts, df)\n",
    "    dict_pmid_test = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 2000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    json_list_test.append(dict_pmid_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pmid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove everything inside the folder 'Test Data Splits'\n",
    "\n",
    "\n",
    "for filename in os.listdir(path_equity_precision_llm_folder + \"/llm training/Test Data Splits\"):\n",
    "    os.remove(path_equity_precision_llm_folder + \"/llm training/Test Data Splits\" +\"/\" + filename)\n",
    "\n",
    "# Number of splits\n",
    "n_json_splits = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved successfully to OneDrive folder:Test_part1.jsonl\n",
      "JSON file saved successfully to OneDrive folder:Test_part2.jsonl\n",
      "JSON file saved successfully to OneDrive folder:Test_part3.jsonl\n",
      "JSON file saved successfully to OneDrive folder:Test_part4.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Split the JSON data\n",
    "split_index = len(json_list_test) // n_json_splits # n_json_splits to be specified above\n",
    "\n",
    "for i in range(n_json_splits):\n",
    "    if(i == n_json_splits-1):\n",
    "        part = json_list_test[i*split_index:]\n",
    "    else:\n",
    "        part = json_list_test[i*split_index:(i+1)*split_index]\n",
    "    with(open(path_equity_precision_llm_folder + '/llm training/Test Data Splits/' + f\"Test_part{i+1}.jsonl\", 'w')) as f:\n",
    "        for entry in part:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    print(f\"JSON file saved successfully to OneDrive folder:\" + f\"Test_part{i+1}.jsonl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Uploading Your Batch Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "inputs_file_path = path_equity_precision_llm_repo + \"/Inputs.txt\"\n",
    "\n",
    "if not os.path.exists(inputs_file_path):\n",
    "    with open(inputs_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "\n",
    "with open(inputs_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "for i in range(n_json_splits):\n",
    "    batch_input_file_test_partI = client.files.create(\n",
    "      file = open(path_equity_precision_llm_folder + '/llm training/Test Data Splits/' + f\"Test_part{i+1}.jsonl\",\"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "    \n",
    "    with open(inputs_file_path, \"a\") as f:\n",
    "      f.write(f\"batch_input_file_test_part{i+1} = '{batch_input_file_test_partI.id}'\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to Inputs.txt and enter each batch_input_file_test_partXX_id at a time in the next code chunk.     \n",
    "For example:    \n",
    "batch_input_file_test_partI_id = \"file-GNgYAgwqibtGtLZ7tDoHYr\"\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-MEH4Ly2TgTfoVRs283XvZJ\n"
     ]
    }
   ],
   "source": [
    "# Enter the batch_input_file_test_partI_id from the Inputs.txt file\n",
    "batch_input_file_test_part4_id = \"file-MEH4Ly2TgTfoVRs283XvZJ\"\n",
    "part = 4 # This needs to be changed to the part number\n",
    "\n",
    "\n",
    "print(batch_input_file_test_part4_id)\n",
    "batch_created_test_part4 = client.batches.create(\n",
    "    input_file_id=batch_input_file_test_part4_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"test data for PMID query - scenario 4 part 4\" + str(part)\n",
    "    }\n",
    ")\n",
    "\n",
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_test_part{part}_id = '{batch_created_test_part4.id}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Checking the Status of a Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to Batches.txt and enter the bacth_Created_test_partI_id for each part.    \n",
    "Example:    \n",
    "batch_created_test_partI_id = 'file-GNgYAgwqibtGtLZ7tDoHYr'    \n",
    "part = 1 # This needs to be changed to the part number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4: completed\n"
     ]
    }
   ],
   "source": [
    "# batch_created_test_partI_id = batch_created_test_partI.id\n",
    "batch_created_test_part2_id = 'batch_67b679736cb88190826795d4d28b08fd'\n",
    "part = 2 # This needs to be changed to the part number\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "\n",
    "batch_status_test_part2 = client.batches.retrieve(batch_created_test_part2_id)\n",
    "\n",
    "print(\"Scenario 4: \" + batch_status_test_part2.status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_test_part1_id = 'batch_67b66cf9833c8190a3e67e081f9298c9'\n",
    "batch_created_test_part2_id = 'batch_67b679736cb88190826795d4d28b08fd'\n",
    "batch_created_test_part3_id = 'batch_67b6802fec0481908c84063ba49399fc'\n",
    "batch_created_test_part4_id = 'batch_67b682351dc081909e053ce05d48278e'\n",
    "\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_test_part1 = client.files.content(batch_status_test_part1.output_file_id)\n",
    "file_response_test_part2 = client.files.content(batch_status_test_part2.output_file_id)\n",
    "file_response_test_part3 = client.files.content(batch_status_test_part3.output_file_id)\n",
    "file_response_test_part4 = client.files.content(batch_status_test_part4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:6: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results4_part1 = format_gpt_output(file_response_test_part1)\n",
    "results4_part1.to_csv(path_equity_precision_llm_folder + '/llm training/Test Data Splits/Test Part ' + str(1) +'_results.csv', index=False)\n",
    "\n",
    "results4_part2 = format_gpt_output(file_response_test_part2)\n",
    "results4_part2.to_csv(path_equity_precision_llm_folder + '/llm training/Test Data Splits/Test Part ' + str(2) +'_results.csv', index=False)\n",
    "\n",
    "results4_part3 = format_gpt_output(file_response_test_part3)\n",
    "results4_part3.to_csv(path_equity_precision_llm_folder + '/llm training/Test Data Splits/Test Part ' + str(3) +'_results.csv', index=False)\n",
    "\n",
    "results4_part4 = format_gpt_output(file_response_test_part4)\n",
    "results4_part4.to_csv(path_equity_precision_llm_folder + '/llm training/Test Data Splits/Test Part ' + str(4) +'_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
