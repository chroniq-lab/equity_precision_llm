{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "\n",
    "if os.getlogin()==\"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif os.getlogin()=='aamnasoniwala':\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"\\llm training\\Test Data Splits\\Test Part \"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path_test = path_equity_precision_llm_folder + \"/llm training/epldat03_Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/clean_input.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/standardize_population.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/adjusted_source_population_match.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = clean_input(input_path = excel_path_test, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "n_json_splits = 4\n",
    "# Concatenate multiple CSVs\n",
    "results = None\n",
    "for scenario in range(1, n_json_splits + 1):\n",
    "    file_path = f\"{path_equity_precision_llm_folder}/llm training/Test Data Splits/Test Part {scenario}_results.csv\"\n",
    "    temp_df = pd.read_csv(file_path)\n",
    "\n",
    "    if results is None:\n",
    "        results = temp_df\n",
    "    else:\n",
    "        results = pd.concat([results, temp_df], ignore_index=True)\n",
    "\n",
    "# Merge datasets\n",
    "merged_df_test = input_test.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "# Standardize source population categories: now loaded from execfile(path_equity_precision_llm_repo + \"/functions/standardize_population.py\")\n",
    "# def standardize_population(value):\n",
    "#     if pd.isna(value) or value.strip().lower() in [\"unknown\", \"not applicable\", \"n/a\", \"N/A\", \"unk\", \"not specified\", \"Unknown\", \"Not Applicable\", \"Not Specified\"]:\n",
    "#         return \"Unknown\"\n",
    "#     return value.strip()\n",
    "\n",
    "merged_df_test['orig_source_population'] = merged_df_test['orig_source_population'].apply(standardize_population)\n",
    "merged_df_test['gpt_source_population'] = merged_df_test['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "# Function for classification comparison: now loaded from execfile(path_equity_precision_llm_repo + \"/functions/adjusted_source_population_match.py\")\n",
    "# def adjusted_source_population_match(row):\n",
    "#     \"\"\"\n",
    "#     Adjusted logic for source population matching:\n",
    "#     - If either column is NaN or categorized as \"Unknown\", classify it as 'Unknown'.\n",
    "#     - Match is True if GPT's classification contains at least one exact category from the original classification.\n",
    "#     \"\"\"\n",
    "#     orig_population = row['orig_source_population']\n",
    "#     gpt_population = row['gpt_source_population']\n",
    "    \n",
    "#     orig_set = set(orig_population.split(', '))\n",
    "#     gpt_set = set(gpt_population.split(', '))\n",
    "\n",
    "#     # If GPT predicted 'Unknown', it doesn't match any known category.\n",
    "#     if gpt_population == 'Unknown':\n",
    "#         return orig_population == 'Unknown'  # Only match if both are 'Unknown'\n",
    "\n",
    "#     # Match only if GPT contains at least one exact category from the original classification\n",
    "#     return any(category in orig_set for category in gpt_set)\n",
    "\n",
    "\n",
    "merged_df_test['source_population_match'] = merged_df_test.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "# Crosstab summary for precision medicine\n",
    "summary_precision_medicine = crosstab_summary(merged_df_test, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "summary_diabetes = crosstab_summary(merged_df_test, truth='orig_diabetes', test='gpt_diabetes')\n",
    "summary_primary_study = crosstab_summary(merged_df_test, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "summary_diabetes['variable'] = 'Diabetes'\n",
    "summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "# Generate updated crosstab for source population\n",
    "t_source_population = pd.crosstab(merged_df_test['source_population_match'], merged_df_test['orig_source_population'])\n",
    "\n",
    "prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "prop_correct_source_population\n",
    "\n",
    "summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study])\n",
    "\n",
    "df_summary = pd.concat([df_summary,summary_source_population])\n",
    "\n",
    "df_summary.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl04_combined output_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = merged_df_test[merged_df_test['source_population_match'] == False]\n",
    "mismatches.to_csv(path_equity_precision_llm_folder + \"/llm training/epl04_mismatched_rows.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
