{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "\n",
    "if os.getlogin()==\"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif os.getlogin()=='aamnasoniwala':\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "# path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "# path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"\\llm training\\Test Data Splits\\Test Part \"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path_test = path_equity_precision_llm_folder + \"/llm training/epldat03_Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/clean_input.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/standardize_population.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/adjusted_source_population_match.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig_source_population\n",
       "unknown                       442\n",
       "lac                           369\n",
       "ea                            362\n",
       "sa                            312\n",
       "na                            184\n",
       "cee                            91\n",
       "we                             83\n",
       "mena                           78\n",
       "seap                           66\n",
       "ca                             56\n",
       "ssa                            14\n",
       "ssa, na, we, lac                2\n",
       "we, na                          2\n",
       "na, we                          2\n",
       "mena, na                        1\n",
       "lac, ssa                        1\n",
       "we, lac                         1\n",
       "cee, ssa, seap, lac             1\n",
       "na, we, ea                      1\n",
       "ssa, na, lac, seap              1\n",
       "na, ea                          1\n",
       "ssa, na, seap, ea, we, lac      1\n",
       "we, mena, ssa                   1\n",
       "we, ssa, na                     1\n",
       "na, ssa, we                     1\n",
       "na, ssa, we, lac                1\n",
       "we, ssa, na, lac                1\n",
       "ea, na                          1\n",
       "na, ssa, ea, we                 1\n",
       "we, ssa, lac, na                1\n",
       "na, ssa, lac, we                1\n",
       "we, na, lac, ea, seap           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = clean_input(input_path=excel_path_test, sheet_name='Sheet1')\n",
    "\n",
    "input_test['orig_source_population'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "n_json_splits = 4\n",
    "results = None\n",
    "\n",
    "# Concatenate multiple CSVs\n",
    "for scenario in range(1, n_json_splits + 1):\n",
    "    file_path = f\"{path_equity_precision_llm_folder}/llm training/Test Data Splits/Test Part {scenario}_results.csv\"\n",
    "    temp_df = pd.read_csv(file_path, na_values=['n/a','NaN'], keep_default_na=False)\n",
    "\n",
    "    if results is None:\n",
    "        results = temp_df\n",
    "    else:\n",
    "        results = pd.concat([results, temp_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_source_population\n",
      "ea                    404\n",
      "lac                   329\n",
      "NaN                   259\n",
      "sa                    256\n",
      "na                    252\n",
      "                     ... \n",
      "we, lac, seap, na       1\n",
      "sa, ea, we              1\n",
      "lac, sa, ssa, seap      1\n",
      "na, ssa, lac, ea        1\n",
      "mena, ssa               1\n",
      "Name: count, Length: 92, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df_test = input_test.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "# merged_df_test['orig_source_population'].value_counts(dropna=False)\n",
    "print(merged_df_test['gpt_source_population'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2076, 17)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge datasets\n",
    "\n",
    "# Standardize source population categories\n",
    "merged_df_test['orig_source_population'] = merged_df_test['orig_source_population'].apply(standardize_population)\n",
    "merged_df_test['gpt_source_population'] = merged_df_test['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "# Classification comparison\n",
    "merged_df_test['source_population_match'] = merged_df_test.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "merged_df_test = merged_df_test.drop_duplicates(subset='PMID', keep='first').reset_index(drop=True)\n",
    "\n",
    "merged_df_test.to_csv(f\"{path_equity_precision_llm_folder}/llm training/epl04_merged_test_data.csv\", index=False)\n",
    "merged_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab summaries for individual conditions\n",
    "summary_precision_medicine = crosstab_summary(merged_df_test, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "summary_diabetes = crosstab_summary(merged_df_test, truth='orig_diabetes', test='gpt_diabetes')\n",
    "summary_primary_study = crosstab_summary(merged_df_test, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "summary_diabetes['variable'] = 'Diabetes'\n",
    "summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "# Source population accuracy\n",
    "t_source_population = pd.crosstab(merged_df_test['source_population_match'], merged_df_test['orig_source_population'])\n",
    "prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "summary_source_population = pd.DataFrame({'variable': ['Source Population'],\n",
    "                                          'Accuracy': [prop_correct_source_population]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall total accuracy\n",
    "merged_df_test['all_conditions_correct'] = (\n",
    "    (merged_df_test['orig_precision_medicine'] == merged_df_test['gpt_precision_medicine']) &\n",
    "    (merged_df_test['orig_diabetes'] == merged_df_test['gpt_diabetes']) &\n",
    "    (merged_df_test['orig_primary_study'] == merged_df_test['gpt_primary_study'])\n",
    ")\n",
    "\n",
    "overall_accuracy = merged_df_test['all_conditions_correct'].mean()\n",
    "summary_overall_conditions = pd.DataFrame({\n",
    "    'variable': ['Overall Conditions (Precision Medicine, Diabetes, Primary Study)'],\n",
    "    'Accuracy': [overall_accuracy]\n",
    "})\n",
    "\n",
    "# Combine all summaries into one df\n",
    "df_summary = pd.concat([\n",
    "    summary_precision_medicine,\n",
    "    summary_diabetes,\n",
    "    summary_primary_study,\n",
    "    summary_source_population,\n",
    "    summary_overall_conditions\n",
    "])\n",
    "\n",
    "# Save combined output\n",
    "df_summary.to_csv(f\"{path_equity_precision_llm_repo}/preprocessing/epl04_combined output_Test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
