{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.14.2 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/epldat03_Unattributable Data.csv\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_csv(excel_path)['PMID'].tolist()\n",
    "\n",
    "json_list_unattributable = []\n",
    "\n",
    "# Step 1: Read the excel sheet\n",
    "if excel_path.endswith('.xlsx') or excel_path.endswith('.xls'):\n",
    "    df = pd.read_excel(excel_path, sheet_name= \"Sheet1\")\n",
    "elif excel_path.endswith('.csv'):\n",
    "    df = pd.read_csv(excel_path,sep=',')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format. Please provide an Excel or CSV file.\")\n",
    "\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    print(pmid)\n",
    "    prompt_pmid = prompt_generator_v2(pmid, base_prompts, df)\n",
    "    dict_pmid_unattributable = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 2000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    json_list_unattributable.append(dict_pmid_unattributable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove everything inside the folder 'Test Data Splits'\n",
    "\n",
    "\n",
    "for filename in os.listdir(path_equity_precision_llm_folder + \"/llm training/Unclassified Splits\"):\n",
    "    os.remove(path_equity_precision_llm_folder + \"/llm training/Unclassified Splits\" +\"/\" + filename)\n",
    "\n",
    "# Number of splits\n",
    "n_json_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Split the JSON data\n",
    "split_index = len(json_list_unattributable) // n_json_splits # n_json_splits to be specified above\n",
    "\n",
    "for i in range(n_json_splits):\n",
    "    part = json_list_unattributable[i*split_index:(i+1)*split_index]\n",
    "    with(open(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/' + f\"Unattributable_part{i+1}.jsonl\", 'w')) as f:\n",
    "        for entry in part:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    print(f\"JSON file saved successfully to OneDrive folder:\" + f\"Unattributable_part{i+1}.jsonl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "inputs_file_path = path_equity_precision_llm_repo + \"/Inputs.txt\"\n",
    "\n",
    "if not os.path.exists(inputs_file_path):\n",
    "    with open(inputs_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "\n",
    "with open(inputs_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "for i in range(n_json_splits):\n",
    "    batch_input_file_unattributable_part1 = client.files.create(\n",
    "      file = open(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/' + f\"Unattributable_part{i+1}.jsonl\",\"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "    \n",
    "    with open(inputs_file_path, \"a\") as f:\n",
    "      f.write(f\"batch_input_file_unattributable_part{i+1} = '{batch_input_file_unattributable_part1.id}'\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the batch_input_file_test_partI_id from the Inputs.txt file\n",
    "batch_input_file_unattributable_part1_id = \"file-MEH4Ly2TgTfoVRs283XvZJ\"\n",
    "part = 1 # This needs to be changed to the part number\n",
    "\n",
    "\n",
    "print(batch_input_file_unattributable_part1_id)\n",
    "batch_created_unattributable_part1 = client.batches.create(\n",
    "    input_file_id=batch_input_file_unattributable_part1_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"unattributable data for PMID query - scenario 4 part 4\" + str(part)\n",
    "    }\n",
    ")\n",
    "\n",
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_unattributable_part{part}_id = '{batch_created_unattributable_part1.id}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_created_test_partI_id = batch_created_test_partI.id\n",
    "batch_created_unattributable_part1_id = 'batch_67b679736cb88190826795d4d28b08fd'\n",
    "part = 1 # This needs to be changed to the part number\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "\n",
    "batch_status_unattributable_part1 = client.batches.retrieve(batch_created_unattributable_part1_id)\n",
    "\n",
    "print(\"Scenario 4: \" + batch_status_unattributable_part1.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_unattributable_part1_id = 'batch_67b66cf9833c8190a3e67e081f9298c9'\n",
    "batch_created_unattributable_part2_id = 'batch_67b679736cb88190826795d4d28b08fd'\n",
    "batch_created_unattributable_part3_id = 'batch_67b6802fec0481908c84063ba49399fc'\n",
    "batch_created_unattributable_part4_id = 'batch_67b682351dc081909e053ce05d48278e'\n",
    "\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_unattributable_part1 = client.files.content(batch_status_unattributable_part1.output_file_id)\n",
    "file_response_unattributable_part2 = client.files.content(batch_status_unattributable_part2.output_file_id)\n",
    "file_response_unattributable_part3 = client.files.content(batch_status_unattributable_part3.output_file_id)\n",
    "file_response_unattributable_part4 = client.files.content(batch_status_unattributable_part4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results4_part1 = format_gpt_output(file_response_unattributable_part1)\n",
    "results4_part1.to_csv(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/Unattributable Part ' + str(1) +'_results.csv', index=False)\n",
    "\n",
    "results4_part2 = format_gpt_output(file_response_unattributable_part2)\n",
    "results4_part2.to_csv(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/Unattributable Part ' + str(2) +'_results.csv', index=False)\n",
    "\n",
    "results4_part3 = format_gpt_output(file_response_unattributable_part3)\n",
    "results4_part3.to_csv(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/Unattributable Part ' + str(3) +'_results.csv', index=False)\n",
    "\n",
    "results4_part4 = format_gpt_output(file_response_unattributable_part4)\n",
    "results4_part4.to_csv(path_equity_precision_llm_folder + '/llm training/Unclassified Splits/Unattributable Part ' + str(4) +'_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
