{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the OpenAI application programming interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command prompt window:\n",
    ">> pip install openai\n",
    "\n",
    "https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kneed) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kneed) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to outline inclusion criteria for three categories: diabetes, precision medicine, and primary study. \n",
      "\n",
      "Please wait for me to prompt you on what to do based on these criteria.  \n",
      "Here are the inclusion criteria:  \n",
      "\n",
      "DIABETES: Do not exclude any type of diabetes or prediabetes. The presence of certain conditions or risk factors may not definitively confirm that the study is related to diabetes or prediabetes, unless there is a clear link to diabetes pathophysiology, diagnosis, or management. \n",
      "\n",
      "PRECISION MEDICINE: Precision medicine is an assessment of genetic or metabolic state to guide preventive and therapeutic decisions in humans. Exclude epidemiological studies using traditional biomarkers only, focusing on omics (genomics, metabolomics, proteomics, lipidomics etc.) or multi-omics studies. \n",
      "\n",
      "PRIMARY STUDY: All types of studies, other than meta-analysis and systematic reviews, were evaluated as primary studies. Although it may bias the studies towards counting contributions of large biorepositories, secondary analysis of previously collected datasets was also included since these generate novel insights into the pathophysiology of diabetes for source populations that these biorepositories sample from.  \n",
      "Based on the PMID, title, abstract, and MeSH terms below and the previously described inclusion criteria, identify using 'yes' or 'no' as categorizations if the article fulfills the criteria for precision medicine, diabetes, and primary study. \n",
      "\n",
      "PMID: 22744164\n",
      "\n",
      "Title: Acculturation and glycemic control of Asian Indian adults with type 2 diabetes \n",
      "\n",
      "Abstract: The prevalence of type 2 diabetes is disproportionately high among Asian Indians (AI), one of the fastest growing immigrant groups in the United States (US). Poorly controlled diabetes associated with inadequate self-management increases complications and thus medical costs. Acculturation may be an important determinant of diabetes self-management and hence control. This study examined the association between the degree of acculturation and glycemic control as measured by Hemoglobin A1c in AI adults with type 2 diabetes. A mixed method (quantitative and qualitative) study was conducted among 30 AI adults with type 2 diabetes. Acculturation assessment using the Suinn-Lew Asian Self-identity Instrument was followed by socio-demographic questions, self-reported anthropometric measures, and open ended diabetes self-care questions. A two-step multiple regression analysis and content analysis of verbatim interview transcriptions were conducted. Interactions of acculturation with body mass index (interaction b = 1.11; p = 0.01), annual household income (interaction b = 7.19; p = .01), and diabetes duration (interaction b = .30; p = .02) significantly predicted higher HbA1c levels (R(2) change = .368; F change = 4.21; p = .02). From the qualitative interviews, the following were regarded as US specific facilitators for glycemic control: excellent health care system and facilities, availability of healthy food choices and self-monitoring devices, medical insurance benefits, good quality medications, and improved health awareness. Cultural orientation might be important for patient tailored interventions targeting AI with type 2 diabetes. Therefore, interventions targeted at Asian Indians with diabetes should include culture specific adaptations to nutrition education and support.    \n",
      "\n",
      "MeSH: Acculturation*; Asian / psychology; Asian / statistics & numerical data*; Body Mass Index; Diabetes Mellitus, Type 2 / ethnology; Diabetes Mellitus, Type 2 / therapy*; Diet / statistics & numerical data; Female; Glycated Hemoglobin / analysis; Humans; Income / statistics & numerical data; India / ethnology; Male; Middle Aged; Self Care / statistics & numerical data; United States   \n",
      "\n",
      "Organize your analysis of this abstract in a table, with the following columns: PMID, title, precision medicine, diabetes, primary study. Please provide evidence directly from the PMID, title, abstract, and MeSH terms to justify your classifications. \n",
      "Now identify the source population. The correct source population is based on the study participants' racial/ethnic background, regardless of geographic location, and refers to humans specifically. Exclude plants and therapeutics that may originate in the region and non-human animal models. The options are humans descending from Central Asia (CA), Central and Eastern Europe (CEE), East Asia (EA), Latin America & Caribbean (LAC), Middle East & North Africa (MENA), South East Asia & Pacific Islands (SEAP), South Asia (SA), Sub-Saharan Africa (SSA), the United States of America and Canada (NA), or Western Europe (WE). \n",
      "\n",
      "Add the classification of the source population to the table in a separate column. You may only use the abbreviation of the source populations provided. \n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)\n",
    "\n",
    "prompt_pmid = prompt_generator(22744164, base_prompts, excel_path)\n",
    "\n",
    "\n",
    "print(base_prompts[0])\n",
    "print(base_prompts[1])\n",
    "print(prompt_pmid)\n",
    "print(base_prompts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Your Batch File\n",
    "\n",
    "https://platform.openai.com/docs/guides/batch\n",
    "\n",
    ".jsonl file where each line contains the details of an individual request to the API\n",
    "\n",
    "Each request must include a custom_id value\n",
    "\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_excel(excel_path, sheet_name='Training Data')['PMID'].tolist()\n",
    "\n",
    "json_list_scenario1 = []\n",
    "json_list_scenario2 = []\n",
    "json_list_scenario3 = []\n",
    "json_list_scenario4 = []\n",
    "\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    prompt_pmid = prompt_generator(pmid, base_prompts, excel_path)\n",
    "    dict_pmid_scenario1 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario2 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario3 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    dict_pmid_scenario4 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-2024-08-06\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    json_list_scenario1.append(dict_pmid_scenario1)\n",
    "    \n",
    "    json_list_scenario2.append(dict_pmid_scenario2)\n",
    "\n",
    "    json_list_scenario3.append(dict_pmid_scenario3)\n",
    "\n",
    "    json_list_scenario4.append(dict_pmid_scenario4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/3098053312.py:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', 'w') as outfile:\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/3098053312.py:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', 'w') as outfile:\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/3098053312.py:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', 'w') as outfile:\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/3098053312.py:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', 'w') as outfile:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario1:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario2:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario3:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario4:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uploading Your Batch Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/1628919600.py:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', \"rb\"),\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/1628919600.py:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', \"rb\"),\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/1628919600.py:17: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', \"rb\"),\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/1628919600.py:22: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', \"rb\"),\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, APIConnectionError\n",
    "\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "try:\n",
    "    batch_input_file_scenario1 = client.files.create(\n",
    "      file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', \"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_scenario2 = client.files.create(\n",
    "      file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', \"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_scenario3 = client.files.create(\n",
    "      file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', \"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_scenario4 = client.files.create(\n",
    "      file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', \"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "except APIConnectionError as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-SWjE7cjyhaiVMKxu7GbvFd\n",
      "file-SWjE7cjyhaiVMKxu7GbvFd\n",
      "file-EJrn4WncHi1qgf8rc3DXbd\n",
      "file-WrctC3jjQ1oxMZxZL7fufY\n"
     ]
    }
   ],
   "source": [
    "batch_input_file_scenario1_id = batch_input_file_scenario1.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario1 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario1_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario2_id = batch_input_file_scenario2.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario2 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario2_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 2\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario3_id = batch_input_file_scenario3.id\n",
    "print(batch_input_file_scenario3_id)\n",
    "batch_created_scenario3 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario3_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 3\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario4_id = batch_input_file_scenario4.id\n",
    "print(batch_input_file_scenario4_id)\n",
    "batch_created_scenario4 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario4_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_id_scenario1 = '{batch_created_scenario1.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario2 = '{batch_created_scenario2.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario3 = '{batch_created_scenario3.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario4 = '{batch_created_scenario4.id}'\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_scenario1_id = batch_created_scenario1.id\n",
    "batch_created_scenario2_id = batch_created_scenario2.id\n",
    "batch_created_scenario3_id = batch_created_scenario3.id\n",
    "batch_created_scenario4_id = batch_created_scenario4.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking the Status of a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: completed; Scenario 2: completed; Scenario 3:expired; Scenario 4:failed\n"
     ]
    }
   ],
   "source": [
    "# batch_created_id = 'batch_675d9dc3f25881909544964060c659c3'\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_status_scenario1 = client.batches.retrieve(batch_created_scenario1_id)\n",
    "batch_status_scenario2 = client.batches.retrieve(batch_created_scenario2_id)\n",
    "batch_status_scenario3 = client.batches.retrieve(batch_created_scenario3_id)\n",
    "\n",
    "batch_status_scenario4 = client.batches.retrieve(batch_created_scenario4_id)\n",
    "\n",
    "print(\"Scenario 1: \" + batch_status_scenario1.status + \"; Scenario 2: \" + batch_status_scenario2.status + \"; Scenario 3:\" + batch_status_scenario3.status + \"; Scenario 4:\" + batch_status_scenario4.status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a non-empty value for `file_id` but received None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m file_response_scenario2 \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcontent(batch_status_scenario2\u001b[38;5;241m.\u001b[39moutput_file_id)\n\u001b[1;32m      5\u001b[0m file_response_scenario3 \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcontent(batch_status_scenario3\u001b[38;5;241m.\u001b[39moutput_file_id)\n\u001b[0;32m----> 6\u001b[0m file_response_scenario4 \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_status_scenario4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_file_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/files.py:288\u001b[0m, in \u001b[0;36mFiles.content\u001b[0;34m(self, file_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mReturns the contents of the specified file.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_id:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `file_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/binary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    292\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39m_legacy_response\u001b[38;5;241m.\u001b[39mHttpxBinaryResponseContent,\n\u001b[1;32m    296\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a non-empty value for `file_id` but received None"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_scenario1 = client.files.content(batch_status_scenario1.output_file_id)\n",
    "file_response_scenario2 = client.files.content(batch_status_scenario2.output_file_id)\n",
    "file_response_scenario3 = client.files.content(batch_status_scenario3.output_file_id)\n",
    "file_response_scenario4 = client.files.content(batch_status_scenario4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4_results.csv', index=False)\n",
      "/Users/aamnasoniwala/code/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:10: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:11: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:12: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3_results.csv', index=False)\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_10911/2422423348.py:13: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4_results.csv', index=False)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/internals/managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m execfile(path_equity_precision_llm_repo \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/functions/format_gpt_output.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m results1 \u001b[38;5;241m=\u001b[39m \u001b[43mformat_gpt_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_response_scenario1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m results2 \u001b[38;5;241m=\u001b[39m format_gpt_output(file_response_scenario2)\n\u001b[1;32m      5\u001b[0m results3 \u001b[38;5;241m=\u001b[39m format_gpt_output(file_response_scenario3)\n",
      "File \u001b[0;32m~/code/equity_precision_llm/functions/format_gpt_output.py:15\u001b[0m, in \u001b[0;36mformat_gpt_output\u001b[0;34m(json_output)\u001b[0m\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(pd\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39mStringIO(markdown_table\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]), \n\u001b[1;32m     11\u001b[0m                   sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, skipinitialspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     12\u001b[0m                   skipfooter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m     out\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results,\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m])\n\u001b[1;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(?!unnamed)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Rename 'precision medicine' as 'precision_medicine'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results1 = format_gpt_output(file_response_scenario1)\n",
    "results2 = format_gpt_output(file_response_scenario2)\n",
    "results3 = format_gpt_output(file_response_scenario3)\n",
    "results4 = format_gpt_output(file_response_scenario4)\n",
    "\n",
    "\n",
    "\n",
    "results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1_results.csv', index=False)\n",
    "results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2_results.csv', index=False)\n",
    "results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3_results.csv', index=False)\n",
    "results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>gpt_precision_medicine</th>\n",
       "      <th>gpt_diabetes</th>\n",
       "      <th>gpt_primary_study</th>\n",
       "      <th>gpt_source_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22744164</td>\n",
       "      <td>Acculturation and glycemic control of Asian I...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15561964</td>\n",
       "      <td>Linkage analysis of diabetes status among hyp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28770629</td>\n",
       "      <td>Ipragliflozin, a sodium glucose co-transporte...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33764184</td>\n",
       "      <td>Gastrodin protects against high glucose-induc...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36155119</td>\n",
       "      <td>Curcumin supplementation reduces blood glucos...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>lac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "1  22744164   Acculturation and glycemic control of Asian I...   \n",
       "1  15561964   Linkage analysis of diabetes status among hyp...   \n",
       "1  28770629   Ipragliflozin, a sodium glucose co-transporte...   \n",
       "1  33764184   Gastrodin protects against high glucose-induc...   \n",
       "1  36155119   Curcumin supplementation reduces blood glucos...   \n",
       "\n",
       "  gpt_precision_medicine gpt_diabetes gpt_primary_study gpt_source_population  \n",
       "1                     no          yes               yes                    sa  \n",
       "1                    yes          yes               yes                    na  \n",
       "1                     no          yes               yes                    ea  \n",
       "1                    yes          yes               yes                    na  \n",
       "1                     no          yes               yes                   lac  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
