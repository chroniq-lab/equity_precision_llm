{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the OpenAI application programming interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command prompt window:\n",
    ">> pip install openai\n",
    "\n",
    "https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.14.2 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jvargh7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kneed) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "import datetime as datetime\n",
    "# Ensure all necessary packages are installed\n",
    "%pip install kneed\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "if user == \"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif user == \"aamnasoniwala\":\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/Desktop/equity_precision_llm'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized user\")\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_epl_shared = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "# https://stackoverflow.com/questions/36959031/how-to-source-file-into-python-script\n",
    "execfile(path_equity_precision_llm_repo + \"/constants.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to outline inclusion criteria for three categories: diabetes, precision medicine, and primary study. \n",
      "\n",
      "Please wait for me to prompt you on what to do based on these criteria.  \n",
      "Here are the inclusion criteria:  \n",
      "\n",
      "DIABETES: Do not exclude any type of diabetes or prediabetes. The presence of certain conditions or risk factors may not definitively confirm that the study is related to diabetes or prediabetes, unless there is a clear link to diabetes pathophysiology, diagnosis, or management. \n",
      "\n",
      "PRECISION MEDICINE: Precision medicine is an assessment of genetic or metabolic state to guide preventive and therapeutic decisions in humans. Exclude epidemiological studies using traditional biomarkers only, focusing on omics (genomics, metabolomics, proteomics, lipidomics etc.) or multi-omics studies. \n",
      "\n",
      "PRIMARY STUDY: All types of studies, other than meta-analysis and systematic reviews, were evaluated as primary studies. Although it may bias the studies towards counting contributions of large biorepositories, secondary analysis of previously collected datasets was also included since these generate novel insights into the pathophysiology of diabetes for source populations that these biorepositories sample from.  \n",
      "Based on the PMID, title, abstract, and MeSH terms below and the previously described inclusion criteria, identify using 'yes' or 'no' as categorizations if the article fulfills the criteria for precision medicine, diabetes, and primary study. \n",
      "\n",
      "PMID: 22744164\n",
      "\n",
      "Title: Acculturation and glycemic control of Asian Indian adults with type 2 diabetes \n",
      "\n",
      "Abstract: The prevalence of type 2 diabetes is disproportionately high among Asian Indians (AI), one of the fastest growing immigrant groups in the United States (US). Poorly controlled diabetes associated with inadequate self-management increases complications and thus medical costs. Acculturation may be an important determinant of diabetes self-management and hence control. This study examined the association between the degree of acculturation and glycemic control as measured by Hemoglobin A1c in AI adults with type 2 diabetes. A mixed method (quantitative and qualitative) study was conducted among 30 AI adults with type 2 diabetes. Acculturation assessment using the Suinn-Lew Asian Self-identity Instrument was followed by socio-demographic questions, self-reported anthropometric measures, and open ended diabetes self-care questions. A two-step multiple regression analysis and content analysis of verbatim interview transcriptions were conducted. Interactions of acculturation with body mass index (interaction b = 1.11; p = 0.01), annual household income (interaction b = 7.19; p = .01), and diabetes duration (interaction b = .30; p = .02) significantly predicted higher HbA1c levels (R(2) change = .368; F change = 4.21; p = .02). From the qualitative interviews, the following were regarded as US specific facilitators for glycemic control: excellent health care system and facilities, availability of healthy food choices and self-monitoring devices, medical insurance benefits, good quality medications, and improved health awareness. Cultural orientation might be important for patient tailored interventions targeting AI with type 2 diabetes. Therefore, interventions targeted at Asian Indians with diabetes should include culture specific adaptations to nutrition education and support.    \n",
      "\n",
      "MeSH: Acculturation*; Asian / psychology; Asian / statistics & numerical data*; Body Mass Index; Diabetes Mellitus, Type 2 / ethnology; Diabetes Mellitus, Type 2 / therapy*; Diet / statistics & numerical data; Female; Glycated Hemoglobin / analysis; Humans; Income / statistics & numerical data; India / ethnology; Male; Middle Aged; Self Care / statistics & numerical data; United States   \n",
      "\n",
      "Organize your analysis of this abstract in a table, with the following columns: PMID, title, precision medicine, diabetes, primary study. Please provide evidence directly from the PMID, title, abstract, and MeSH terms to justify your classifications. \n",
      "Now identify the source population. The correct source population is based on the study participants' racial/ethnic background, regardless of geographic location, and refers to humans specifically. Exclude plants and therapeutics that may originate in the region and non-human animal models. The options are humans descending from Central Asia (CA), Central and Eastern Europe (CEE), East Asia (EA), Latin America & Caribbean (LAC), Middle East & North Africa (MENA), South East Asia & Pacific Islands (SEAP), South Asia (SA), Sub-Saharan Africa (SSA), the United States of America and Canada (NA), or Western Europe (WE). \n",
      "\n",
      "Add the classification of the source population to the table in a separate column. You may only use the abbreviation of the source populations provided. \n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/prompt_generator.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/base_prompt_append.py\")\n",
    "\n",
    "base_prompt_files = ['p1v6', 'p2v6', 'p3v6','p4v6']\n",
    "base_prompts = base_prompt_append(base_prompt_files)\n",
    "\n",
    "prompt_pmid = prompt_generator(22744164, base_prompts, excel_path)\n",
    "\n",
    "\n",
    "print(base_prompts[0])\n",
    "print(base_prompts[1])\n",
    "print(prompt_pmid)\n",
    "print(base_prompts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Your Batch File\n",
    "\n",
    "https://platform.openai.com/docs/guides/batch\n",
    "\n",
    ".jsonl file where each line contains the details of an individual request to the API\n",
    "\n",
    "Each request must include a custom_id value\n",
    "\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = pd.read_excel(excel_path, sheet_name='Training Data')['PMID'].tolist()\n",
    "\n",
    "json_list_scenario1 = []\n",
    "json_list_scenario2 = []\n",
    "json_list_scenario3 = []\n",
    "json_list_scenario4 = []\n",
    "\n",
    "for index, pmid in enumerate(pmid_list):\n",
    "    prompt_pmid = prompt_generator(pmid, base_prompts, excel_path)\n",
    "    dict_pmid_scenario1 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-mini-2024-07-18\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario2 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-mini-2024-07-18\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"temperature\": 0.2,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    \n",
    "    dict_pmid_scenario3 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-mini-2024-07-18\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": 0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": 0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "\n",
    "    dict_pmid_scenario4 = {\"custom_id\": str(index) + \"_\" + str(pmid), \n",
    "                 \"method\": \"POST\", \n",
    "                 \"url\": \"/v1/chat/completions\", \n",
    "                 \"body\": {\"model\": \"gpt-4o-mini-2024-07-18\", \n",
    "                          \"messages\": [ {\"role\": \"system\", \"content\": base_prompts[0]},\n",
    "                                        {\"role\": \"system\", \"content\": base_prompts[1]},\n",
    "                                        {\"role\": \"user\", \"content\": prompt_pmid},\n",
    "                                        {\"role\": \"user\", \"content\": base_prompts[3]}],\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"frequency_penalty\": -0.2,\n",
    "                            \"top_p\": 0.8,\n",
    "                            \"presence_penalty\": -0.3\n",
    "\n",
    "                        }\n",
    "                }\n",
    "    json_list_scenario1.append(dict_pmid_scenario1)\n",
    "    \n",
    "    json_list_scenario2.append(dict_pmid_scenario2)\n",
    "\n",
    "    json_list_scenario3.append(dict_pmid_scenario3)\n",
    "\n",
    "    json_list_scenario4.append(dict_pmid_scenario4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario1:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario2:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario3:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')\n",
    "\n",
    "with open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', 'w') as outfile:\n",
    "    for entry in json_list_scenario4:\n",
    "        json_line = json.dumps(entry)\n",
    "        outfile.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uploading Your Batch Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_input_file_scenario1 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario2 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario3 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_scenario4 = client.files.create(\n",
    "  file=open(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-1JSSKE7DyJtoH6NgyfaKpT\n",
      "file-1JSSKE7DyJtoH6NgyfaKpT\n",
      "file-AixGuD6tJngzTARxKwMrDS\n",
      "file-3NUegcGHJZzggrTmrDZgM3\n"
     ]
    }
   ],
   "source": [
    "batch_input_file_scenario1_id = batch_input_file_scenario1.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario1 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario1_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario2_id = batch_input_file_scenario2.id\n",
    "print(batch_input_file_scenario1_id)\n",
    "batch_created_scenario2 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario2_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 2\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario3_id = batch_input_file_scenario3.id\n",
    "print(batch_input_file_scenario3_id)\n",
    "batch_created_scenario3 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario3_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 3\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_input_file_scenario4_id = batch_input_file_scenario4.id\n",
    "print(batch_input_file_scenario4_id)\n",
    "batch_created_scenario4 = client.batches.create(\n",
    "    input_file_id=batch_input_file_scenario4_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"training data for PMID query - scenario 4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_file_path = path_equity_precision_llm_repo + \"/Batches.txt\"\n",
    "\n",
    "if not os.path.exists(batches_file_path):\n",
    "    with open(batches_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "with open(batches_file_path, \"a\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    current_time = datetime.datetime.now()\n",
    "    f.write(f\"# {current_time}\\n\")\n",
    "    f.write(f\"batch_created_id_scenario1 = '{batch_created_scenario1.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario2 = '{batch_created_scenario2.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario3 = '{batch_created_scenario3.id}'\\n\")\n",
    "    f.write(f\"batch_created_id_scenario4 = '{batch_created_scenario4.id}'\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_created_scenario1_id = batch_created_scenario1.id\n",
    "batch_created_scenario2_id = batch_created_scenario2.id\n",
    "batch_created_scenario3_id = batch_created_scenario3.id\n",
    "batch_created_scenario4_id = batch_created_scenario4.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking the Status of a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: completed; Scenario 2: completed; Scenario 3:completed; Scenario 4:completed\n"
     ]
    }
   ],
   "source": [
    "# batch_created_id = 'batch_675d9dc3f25881909544964060c659c3'\n",
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "batch_status_scenario1 = client.batches.retrieve(batch_created_scenario1_id)\n",
    "\n",
    "batch_status_scenario2 = client.batches.retrieve(batch_created_scenario2_id)\n",
    "batch_status_scenario3 = client.batches.retrieve(batch_created_scenario3_id)\n",
    "\n",
    "batch_status_scenario4 = client.batches.retrieve(batch_created_scenario4_id)\n",
    "\n",
    "print(\"Scenario 1: \" + batch_status_scenario1.status + \"; Scenario 2: \" + batch_status_scenario2.status + \"; Scenario 3:\" + batch_status_scenario3.status + \"; Scenario 4:\" + batch_status_scenario4.status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= api_key_epl_shared)\n",
    "\n",
    "file_response_scenario1 = client.files.content(batch_status_scenario1.output_file_id)\n",
    "file_response_scenario2 = client.files.content(batch_status_scenario2.output_file_id)\n",
    "file_response_scenario3 = client.files.content(batch_status_scenario3.output_file_id)\n",
    "file_response_scenario4 = client.files.content(batch_status_scenario4.output_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n",
      "C:/code/external/equity_precision_llm/functions/format_gpt_output.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_output.content.decode('utf-8'), lines=True)\n"
     ]
    }
   ],
   "source": [
    "execfile(path_equity_precision_llm_repo + \"/functions/format_gpt_output.py\")\n",
    "\n",
    "results1 = format_gpt_output(file_response_scenario1)\n",
    "results2 = format_gpt_output(file_response_scenario2)\n",
    "results3 = format_gpt_output(file_response_scenario3)\n",
    "results4 = format_gpt_output(file_response_scenario4)\n",
    "\n",
    "\n",
    "\n",
    "results1.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 1_results.csv', index=False)\n",
    "results2.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 2_results.csv', index=False)\n",
    "results3.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 3_results.csv', index=False)\n",
    "results4.to_csv(path_equity_precision_llm_folder + '\\llm training\\Training Scenario 4_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>gpt_precision_medicine</th>\n",
       "      <th>gpt_diabetes</th>\n",
       "      <th>gpt_primary_study</th>\n",
       "      <th>gpt_source_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22744164</td>\n",
       "      <td>Acculturation and glycemic control of Asian I...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15561964</td>\n",
       "      <td>Linkage analysis of diabetes status among hyp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28770629</td>\n",
       "      <td>Ipragliflozin, a sodium glucose co-transporte...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33764184</td>\n",
       "      <td>Gastrodin protects against high glucose-induc...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36155119</td>\n",
       "      <td>Curcumin supplementation reduces blood glucos...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>lac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "1  22744164   Acculturation and glycemic control of Asian I...   \n",
       "1  15561964   Linkage analysis of diabetes status among hyp...   \n",
       "1  28770629   Ipragliflozin, a sodium glucose co-transporte...   \n",
       "1  33764184   Gastrodin protects against high glucose-induc...   \n",
       "1  36155119   Curcumin supplementation reduces blood glucos...   \n",
       "\n",
       "  gpt_precision_medicine gpt_diabetes gpt_primary_study gpt_source_population  \n",
       "1                     no          yes               yes                    sa  \n",
       "1                    yes          yes               yes                    na  \n",
       "1                     no          yes               yes                    ea  \n",
       "1                    yes          yes               yes        not applicable  \n",
       "1                     no          yes               yes                   lac  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
