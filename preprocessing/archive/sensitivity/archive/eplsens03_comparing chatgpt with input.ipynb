{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "\n",
    "# if os.getlogin()==\"JVARGH7\":\n",
    "   # path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "   # path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "# elif os.getlogin()=='aamnasoniwala':\n",
    "   # path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "   # path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "path_equity_precision_llm_folder = \"/Users/sophiakim/Library/CloudStorage/OneDrive-SharedLibraries-Emory/Varghese, Jithin Sam - Global Equity in Diabetes Precision Medicine LLM\"\n",
    "path_equity_precision_llm_repo = '/Users/sophiakim/code/equity_precision_llm'\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/o3-mini training/epldat03_Development Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "# path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "# excel_path_training = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "excel_path_development = path_equity_precision_llm_folder + \"/o3-mini training/epldat03_Development Data.xlsx\"\n",
    "# excel_path_test = path_equity_precision_llm_folder + \"/llm training/Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/clean_input.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_training = clean_input(input_path = excel_path_training, sheet_name='Training Data')\n",
    "input_development = clean_input(input_path = excel_path_development, sheet_name='Sheet1')\n",
    "# input_test = clean_input(input_path = excel_path_test, sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Training (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_76022/3233509646.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  merged_df_training['source_population_match'] = merged_df_training.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# OLD CODE USE CELL BELOW FOR TRAINING \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "combined_output_training = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/o3-mini training/Training Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_training = input_training.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_training['source_population_match'] = merged_df_training.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_training,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_training,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_training,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_training = pd.concat([combined_output_training,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_training.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Overall Accuracy: 0.75\n",
      "Scenario 2 Overall Accuracy: 0.8\n",
      "Scenario 3 Overall Accuracy: 0.8\n",
      "Scenario 4 Overall Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# USE FOR TRAINING\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "combined_output_training = pd.DataFrame()\n",
    "\n",
    "for scenario in range(1, 5):\n",
    "    results = pd.read_csv(f\"{path_equity_precision_llm_folder}/o3-mini training/Training Scenario {scenario}_results.csv\")\n",
    "    merged_df_training = input_training.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "    # Standardize source population categories\n",
    "    def standardize_population(value):\n",
    "        if pd.isna(value) or value.strip().lower() in [\"unknown\", \"not applicable\", \"n/a\", \"unk\", \"not specified\"]:\n",
    "            return \"Unknown\"\n",
    "        return value.strip()\n",
    "\n",
    "    merged_df_training['orig_source_population'] = merged_df_training['orig_source_population'].apply(standardize_population)\n",
    "    merged_df_training['gpt_source_population'] = merged_df_training['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "    # Adjusted classification comparison function\n",
    "    def adjusted_source_population_match(row):\n",
    "        orig_set = set(row['orig_source_population'].split(', '))\n",
    "        gpt_set = set(row['gpt_source_population'].split(', '))\n",
    "\n",
    "        if row['gpt_source_population'] == 'Unknown':\n",
    "            return row['orig_source_population'] == 'Unknown'\n",
    "\n",
    "        return any(category in orig_set for category in gpt_set)\n",
    "\n",
    "    merged_df_training['source_population_match'] = merged_df_training.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "    # Crosstab summaries\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_training, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_training, truth='orig_diabetes', test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_training, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "    # Source population accuracy\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "    summary_source_population = pd.DataFrame({\n",
    "        'variable': ['Source Population'],\n",
    "        'Accuracy': [prop_correct_source_population]\n",
    "    })\n",
    "\n",
    "    # Overall total accuracy\n",
    "    merged_df_training['all_conditions_correct'] = (\n",
    "        (merged_df_training['orig_precision_medicine'] == merged_df_training['gpt_precision_medicine']) &\n",
    "        (merged_df_training['orig_diabetes'] == merged_df_training['gpt_diabetes']) &\n",
    "        (merged_df_training['orig_primary_study'] == merged_df_training['gpt_primary_study'])\n",
    "    )\n",
    "\n",
    "    overall_accuracy = merged_df_training['all_conditions_correct'].mean()\n",
    "    summary_overall_conditions = pd.DataFrame({\n",
    "        'variable': ['Overall Conditions (Precision Medicine, Diabetes, Primary Study)'],\n",
    "        'Accuracy': [overall_accuracy]\n",
    "    })\n",
    "\n",
    "    # Combine summaries\n",
    "    df_summary = pd.concat([\n",
    "        summary_precision_medicine,\n",
    "        summary_diabetes,\n",
    "        summary_primary_study,\n",
    "        summary_source_population,\n",
    "        summary_overall_conditions\n",
    "    ])\n",
    "\n",
    "    df_summary['Scenario'] = f'Scenario{scenario}'\n",
    "\n",
    "    combined_output_training = pd.concat([combined_output_training, df_summary], ignore_index=True)\n",
    "\n",
    "    # Print accuracy per scenario\n",
    "    print(f\"Scenario {scenario} Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Save combined summaries\n",
    "combined_output_training.to_csv(f\"{path_equity_precision_llm_repo}/preprocessing/epl03_combined output_Training.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Development (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE FOR DEV SET\n",
    "combined_output_development = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/o3-mini training/Development Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_development = input_development.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_development['source_population_match'] = merged_df_development.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_development,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_development,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_development,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_development = pd.concat([combined_output_development,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_development.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Development.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Overall Accuracy: 71.00%\n",
      "Scenario 2 Overall Accuracy: 72.00%\n",
      "Scenario 3 Overall Accuracy: 74.00%\n",
      "Scenario 4 Overall Accuracy: 71.00%\n"
     ]
    }
   ],
   "source": [
    "# USE THIS CODE FOR DEV SET\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "combined_output_development = pd.DataFrame()\n",
    "\n",
    "for scenario in range(1, 5):\n",
    "    results = pd.read_csv(f\"{path_equity_precision_llm_folder}/o3-mini training/Development Scenario {scenario}_results.csv\")\n",
    "    merged_df_development = input_development.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "    # Standardize source population categories\n",
    "    def standardize_population(value):\n",
    "        if pd.isna(value) or value.strip().lower() in [\"unknown\", \"not applicable\", \"n/a\", \"unk\", \"not specified\"]:\n",
    "            return \"Unknown\"\n",
    "        return value.strip()\n",
    "\n",
    "    merged_df_development['orig_source_population'] = merged_df_development['orig_source_population'].apply(standardize_population)\n",
    "    merged_df_development['gpt_source_population'] = merged_df_development['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "    # Adjusted classification comparison function\n",
    "    def adjusted_source_population_match(row):\n",
    "        orig_set = set(row['orig_source_population'].split(', '))\n",
    "        gpt_set = set(row['gpt_source_population'].split(', '))\n",
    "\n",
    "        if row['gpt_source_population'] == 'Unknown':\n",
    "            return row['orig_source_population'] == 'Unknown'\n",
    "\n",
    "        return any(category in orig_set for category in gpt_set)\n",
    "\n",
    "    merged_df_development['source_population_match'] = merged_df_development.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "    # Crosstab summaries\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_development, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_development, truth='orig_diabetes', test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_development, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "    # Source population accuracy\n",
    "    t_source_population = pd.crosstab(merged_df_development['source_population_match'], merged_df_development['orig_source_population'])\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "    summary_source_population = pd.DataFrame({'variable': ['Source Population'],\n",
    "                                              'Accuracy': [prop_correct_source_population]})\n",
    "\n",
    "    # Overall total accuracy\n",
    "    merged_df_development['all_conditions_correct'] = (\n",
    "        (merged_df_development['orig_precision_medicine'] == merged_df_development['gpt_precision_medicine']) &\n",
    "        (merged_df_development['orig_diabetes'] == merged_df_development['gpt_diabetes']) &\n",
    "        (merged_df_development['orig_primary_study'] == merged_df_development['gpt_primary_study'])\n",
    "    )\n",
    "\n",
    "    overall_accuracy = merged_df_development['all_conditions_correct'].mean()\n",
    "    summary_overall_conditions = pd.DataFrame({\n",
    "        'variable': ['Overall Conditions (Precision Medicine, Diabetes, Primary Study)'],\n",
    "        'Accuracy': [overall_accuracy]\n",
    "    })\n",
    "\n",
    "    # Combine summaries\n",
    "    df_summary = pd.concat([\n",
    "        summary_precision_medicine,\n",
    "        summary_diabetes,\n",
    "        summary_primary_study,\n",
    "        summary_source_population,\n",
    "        summary_overall_conditions\n",
    "    ])\n",
    "\n",
    "    df_summary['Scenario'] = f'Scenario{scenario}'\n",
    "    combined_output_development = pd.concat([combined_output_development, df_summary], axis=0, ignore_index=True)\n",
    "\n",
    "    # Print accuracy for each scenario\n",
    "    print(f\"Scenario {scenario} Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "# Save the final output\n",
    "combined_output_development.to_csv(f\"{path_equity_precision_llm_repo}/preprocessing/epl03_combined output_Development.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
