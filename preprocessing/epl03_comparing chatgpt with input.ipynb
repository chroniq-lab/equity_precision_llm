{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "\n",
    "if os.getlogin()==\"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif os.getlogin()=='aamnasoniwala':\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "# path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "excel_path_training = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "excel_path_development = path_equity_precision_llm_folder + \"/llm training/epldat03_Development Data.xlsx\"\n",
    "excel_path_test = path_equity_precision_llm_folder + \"/llm training/epldat03_Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/clean_input.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training = clean_input(input_path = excel_path_training, sheet_name='Training Data')\n",
    "input_development = clean_input(input_path = excel_path_development, sheet_name='Sheet1')\n",
    "input_test = clean_input(input_path = excel_path_test, sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>orig_precision_medicine</th>\n",
       "      <th>orig_diabetes</th>\n",
       "      <th>orig_source_population</th>\n",
       "      <th>orig_primary_study</th>\n",
       "      <th>pubmed_source_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23680249</td>\n",
       "      <td>Pattern and predictors of dyslipidemia in pati...</td>\n",
       "      <td>Dyslipidemia is a major risk factor for macro-...</td>\n",
       "      <td>Adult, Blood Glucose, Cross-Sectional Studies,...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "      <td>yes</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32585310</td>\n",
       "      <td>Proteome-wide assessment of diabetes mellitus ...</td>\n",
       "      <td>Proteomics is expected to provide novel insigh...</td>\n",
       "      <td>Adult, Blood Proteins, Case-Control Studies, C...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "      <td>yes</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34254537</td>\n",
       "      <td>Role of Nutrition Counseling and Lifestyle Mod...</td>\n",
       "      <td>Objective: India is the second country after C...</td>\n",
       "      <td>Blood Glucose, Counseling, Diabetes Mellitus, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "      <td>yes</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15287926</td>\n",
       "      <td>Lipids and lipoprotein(a) concentrations in Pa...</td>\n",
       "      <td>The aim of the present study was to analyze se...</td>\n",
       "      <td>Blood Pressure, Case-Control Studies, Diabetes...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "      <td>yes</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16108841</td>\n",
       "      <td>Telomere shortening occurs in Asian Indian Typ...</td>\n",
       "      <td>Telomere shortening has been reported in sever...</td>\n",
       "      <td>Aging, Cholesterol, Diabetes Mellitus, Type 2,...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>sa</td>\n",
       "      <td>yes</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>33786936</td>\n",
       "      <td>Eukaryotic viruses in the fecal virome at the ...</td>\n",
       "      <td>Studies of the fecal virome in type 1 diabetes...</td>\n",
       "      <td>Adolescent, Azerbaijan, Case-Control Studies, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>22151254</td>\n",
       "      <td>Genetic variants in potassium channels are ass...</td>\n",
       "      <td>Recent genome-wide association studies (GWAS) ...</td>\n",
       "      <td>ATP-Binding Cassette Transporters, Alleles, Di...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>32870173</td>\n",
       "      <td>The prevalence of major cardiovascular risk fa...</td>\n",
       "      <td>To study the prevalence of cardiovascular (CV)...</td>\n",
       "      <td>Adolescent, Adult, Aged, Cardiovascular Diseas...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>30255370</td>\n",
       "      <td>Desertiactinospora gelatinilytica gen. nov., s...</td>\n",
       "      <td>A novel, Gram-positive, spore-forming actinomy...</td>\n",
       "      <td>ATP Binding Cassette Transporter, Subfamily B,...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>27420933</td>\n",
       "      <td>Correlation between PPARg2 gene Pro12Ala polym...</td>\n",
       "      <td>The variant of PPAR-g2 has been shown to promo...</td>\n",
       "      <td>Adult, Aged, Aged, 80 and over, Case-Control S...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2081 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PMID                                              Title  \\\n",
       "0     23680249  Pattern and predictors of dyslipidemia in pati...   \n",
       "1     32585310  Proteome-wide assessment of diabetes mellitus ...   \n",
       "2     34254537  Role of Nutrition Counseling and Lifestyle Mod...   \n",
       "3     15287926  Lipids and lipoprotein(a) concentrations in Pa...   \n",
       "4     16108841  Telomere shortening occurs in Asian Indian Typ...   \n",
       "...        ...                                                ...   \n",
       "2076  33786936  Eukaryotic viruses in the fecal virome at the ...   \n",
       "2077  22151254  Genetic variants in potassium channels are ass...   \n",
       "2078  32870173  The prevalence of major cardiovascular risk fa...   \n",
       "2079  30255370  Desertiactinospora gelatinilytica gen. nov., s...   \n",
       "2080  27420933  Correlation between PPARg2 gene Pro12Ala polym...   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     Dyslipidemia is a major risk factor for macro-...   \n",
       "1     Proteomics is expected to provide novel insigh...   \n",
       "2     Objective: India is the second country after C...   \n",
       "3     The aim of the present study was to analyze se...   \n",
       "4     Telomere shortening has been reported in sever...   \n",
       "...                                                 ...   \n",
       "2076  Studies of the fecal virome in type 1 diabetes...   \n",
       "2077  Recent genome-wide association studies (GWAS) ...   \n",
       "2078  To study the prevalence of cardiovascular (CV)...   \n",
       "2079  A novel, Gram-positive, spore-forming actinomy...   \n",
       "2080  The variant of PPAR-g2 has been shown to promo...   \n",
       "\n",
       "                                                   MeSH  \\\n",
       "0     Adult, Blood Glucose, Cross-Sectional Studies,...   \n",
       "1     Adult, Blood Proteins, Case-Control Studies, C...   \n",
       "2     Blood Glucose, Counseling, Diabetes Mellitus, ...   \n",
       "3     Blood Pressure, Case-Control Studies, Diabetes...   \n",
       "4     Aging, Cholesterol, Diabetes Mellitus, Type 2,...   \n",
       "...                                                 ...   \n",
       "2076  Adolescent, Azerbaijan, Case-Control Studies, ...   \n",
       "2077  ATP-Binding Cassette Transporters, Alleles, Di...   \n",
       "2078  Adolescent, Adult, Aged, Cardiovascular Diseas...   \n",
       "2079  ATP Binding Cassette Transporter, Subfamily B,...   \n",
       "2080  Adult, Aged, Aged, 80 and over, Case-Control S...   \n",
       "\n",
       "     orig_precision_medicine orig_diabetes orig_source_population  \\\n",
       "0                         no           yes                     sa   \n",
       "1                         no           yes                     sa   \n",
       "2                         no           yes                     sa   \n",
       "3                         no           yes                     sa   \n",
       "4                         no           yes                     sa   \n",
       "...                      ...           ...                    ...   \n",
       "2076                     yes           yes                     ca   \n",
       "2077                     yes           yes                     ca   \n",
       "2078                      no            no                     ca   \n",
       "2079                     yes            no                unknown   \n",
       "2080                     yes            no                     ca   \n",
       "\n",
       "     orig_primary_study pubmed_source_population  \n",
       "0                   yes                       SA  \n",
       "1                   yes                       SA  \n",
       "2                   yes                       SA  \n",
       "3                   yes                       SA  \n",
       "4                   yes                       SA  \n",
       "...                 ...                      ...  \n",
       "2076                yes                       CA  \n",
       "2077                yes                       CA  \n",
       "2078                yes                       CA  \n",
       "2079                yes                       CA  \n",
       "2080                yes                       CA  \n",
       "\n",
       "[2081 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Training (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_output_training = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/llm training/Training Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_training = input_training.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_training['source_population_match'] = merged_df_training.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_training,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_training,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_training,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_training = pd.concat([combined_output_training,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_training.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Development (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_output_development = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/llm training/Development Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_development = input_development.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_development['source_population_match'] = merged_df_development.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_development,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_development,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_development,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_development['source_population_match'], merged_df_development['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_development = pd.concat([combined_output_development,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_development.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Development.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining different outputs for Test (1 : n_json_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ppv</th>\n",
       "      <th>npv</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871063</td>\n",
       "      <td>0.864991</td>\n",
       "      <td>0.867527</td>\n",
       "      <td>0.859223</td>\n",
       "      <td>0.876415</td>\n",
       "      <td>Precision Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.799599</td>\n",
       "      <td>0.863702</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933838</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.922525</td>\n",
       "      <td>0.985608</td>\n",
       "      <td>0.379147</td>\n",
       "      <td>Primary Study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensitivity  Specificity  Accuracy       ppv       npv            variable\n",
       "0     0.871063     0.864991  0.867527  0.859223  0.876415  Precision Medicine\n",
       "0     0.923077     0.799599  0.863702  0.834437  0.904762            Diabetes\n",
       "0     0.933838     0.747664  0.922525  0.985608  0.379147       Primary Study"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_json_splits = 4\n",
    "results = pd.DataFrame()\n",
    "for part in range(1,n_json_splits+1):\n",
    "    results = pd.concat([results,pd.read_csv(path_equity_precision_llm_folder + '/llm training/Test Data Splits/Test Part '+ str(part) +'_results.csv')])\n",
    "merged_df_test = input_test.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "merged_df_test['source_population_match'] = merged_df_test.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "summary_precision_medicine = crosstab_summary(merged_df_test,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "summary_diabetes = crosstab_summary(merged_df_test,truth='orig_diabetes',test='gpt_diabetes')\n",
    "summary_primary_study = crosstab_summary(merged_df_test,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "summary_diabetes['variable'] = 'Diabetes'\n",
    "summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "t_source_population = pd.crosstab(merged_df_test['source_population_match'], merged_df_test['orig_source_population'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5624103299856528"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "\n",
    "prop_correct_source_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "\n",
    "\n",
    "df_summary.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To review why source population accuracy is low, and for which source populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_source_population  ca  cee  ea  lac  mena  na, ssa  sa  seap  ssa  unk  \\\n",
      "gpt_source_population                                                         \n",
      "cee                      1    1   0    0     1        0   0     0    0    0   \n",
      "cee, we                  0    1   0    0     0        0   0     0    0    0   \n",
      "ea                       0    0   1    0     0        0   0     0    0    0   \n",
      "lac                      0    0   0    2     0        0   0     0    0    0   \n",
      "mena                     0    0   0    0     1        0   0     0    0    0   \n",
      "na                       0    0   0    0     0        1   0     0    1    2   \n",
      "sa                       0    0   0    0     0        0   1     0    0    0   \n",
      "seap                     0    0   0    0     0        0   0     2    0    0   \n",
      "we                       0    0   0    0     0        0   0     0    0    0   \n",
      "\n",
      "orig_source_population  we  \n",
      "gpt_source_population       \n",
      "cee                      0  \n",
      "cee, we                  0  \n",
      "ea                       0  \n",
      "lac                      0  \n",
      "mena                     0  \n",
      "na                       0  \n",
      "sa                       0  \n",
      "seap                     1  \n",
      "we                       1  \n"
     ]
    }
   ],
   "source": [
    "crosstab_result_training = pd.crosstab(merged_df_training['gpt_source_population'], merged_df_training['orig_source_population'])\n",
    "print(crosstab_result_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_result_development = pd.crosstab(merged_df_development['gpt_source_population'], merged_df_development['orig_source_population'])\n",
    "print(crosstab_result_development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_result_test = pd.crosstab(merged_df_test['gpt_source_population'], merged_df_test['orig_source_population'])\n",
    "print(crosstab_result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
