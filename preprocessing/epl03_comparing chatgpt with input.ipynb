{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import os as os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re as re\n",
    "\n",
    "if os.getlogin()==\"JVARGH7\":\n",
    "    path_equity_precision_llm_folder = \"C:/Cloud/OneDrive - Emory University/Papers/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo =  'C:/code/external/equity_precision_llm'\n",
    "\n",
    "elif os.getlogin()=='aamnasoniwala':\n",
    "    path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "    path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "excel_path = path_equity_precision_llm_folder + \"/llm training/epldat03_Development Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_equity_precision_llm_folder = \"/Users/aamnasoniwala/Library/CloudStorage/OneDrive-Emory/Global Equity in Diabetes Precision Medicine LLM\"\n",
    "# path_equity_precision_llm_repo = '/Users/aamnasoniwala/code/equity_precision_llm'\n",
    "\n",
    "# excel_path_training = path_equity_precision_llm_folder + \"/llm training/Methods.xlsx\"\n",
    "excel_path_development = path_equity_precision_llm_folder + \"/llm training/epldat03_Development Data.xlsx\"\n",
    "# excel_path_test = path_equity_precision_llm_folder + \"/llm training/Test Data.xlsx\"\n",
    "# path_equity_precision_llm_repo = os.path.abspath(\"\").replace(\"preprocessing\", \"\")\n",
    "\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/clean_input.py\")\n",
    "execfile(path_equity_precision_llm_repo + \"/functions/crosstab_summary.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_training = clean_input(input_path = excel_path_training, sheet_name='Training Data')\n",
    "input_development = clean_input(input_path = excel_path_development, sheet_name='Sheet1')\n",
    "# input_test = clean_input(input_path = excel_path_test, sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Training (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/k7/_r7nqc9s78jfx1ftfzjxmfwc0000gn/T/ipykernel_76022/3233509646.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  merged_df_training['source_population_match'] = merged_df_training.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# OLD CODE USE CELL BELOW FOR TRAINING \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "combined_output_training = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/llm training/Training Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_training = input_training.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_training['source_population_match'] = merged_df_training.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_training,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_training,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_training,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_training = pd.concat([combined_output_training,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_training.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS FOR TRAINING DATA\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize an empty DataFrame to store combined results\n",
    "combined_output_training = pd.DataFrame()\n",
    "\n",
    "# Loop through training scenarios\n",
    "for scenario in range(1, 5):\n",
    "    results = pd.read_csv(f\"{path_equity_precision_llm_folder}/llm training/Training Scenario {scenario}_results.csv\")\n",
    "    merged_df_training = input_training.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "    # Standardize source population categories\n",
    "    def standardize_population(value):\n",
    "        if pd.isna(value) or value.strip().lower() in [\"unknown\", \"not applicable\", \"n/a\", \"N/A\", \"unk\", \"not specified\", \"Unknown\", \"Not Applicable\", \"Not Specified\"]:\n",
    "            return \"Unknown\"\n",
    "        return value.strip()\n",
    "\n",
    "    merged_df_training['orig_source_population'] = merged_df_training['orig_source_population'].apply(standardize_population)\n",
    "    merged_df_training['gpt_source_population'] = merged_df_training['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "    # Function for adjusted classification comparison\n",
    "    def adjusted_source_population_match(row):\n",
    "        \"\"\"\n",
    "        Adjusted logic for source population matching:\n",
    "        - If either column is NaN or categorized as \"Unknown\", classify it as 'Unknown'.\n",
    "        - Match is True if GPT's classification contains at least one exact category from the original classification.\n",
    "        \"\"\"\n",
    "        orig_population = row['orig_source_population']\n",
    "        gpt_population = row['gpt_source_population']\n",
    "        \n",
    "        orig_set = set(orig_population.split(', '))\n",
    "        gpt_set = set(gpt_population.split(', '))\n",
    "\n",
    "        # If GPT predicted 'Unknown', it doesn't match any known category.\n",
    "        if gpt_population == 'Unknown':\n",
    "            return orig_population == 'Unknown'  # Only match if both are 'Unknown'\n",
    "\n",
    "        # Match only if GPT contains at least one exact category from the original classification\n",
    "        return any(category in orig_set for category in gpt_set)\n",
    "\n",
    "    # Apply the updated matching logic\n",
    "    merged_df_training['source_population_match'] = merged_df_training.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_training, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_training, truth='orig_diabetes', test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_training, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "    # Generate updated crosstab for source population\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study, summary_source_population])\n",
    "    df_summary['Scenario'] = f'Scenario{scenario}'\n",
    "    combined_output_training = pd.concat([combined_output_training, df_summary], axis=0, ignore_index=True)\n",
    "\n",
    "# Save the final output\n",
    "combined_output_training.to_csv(f\"{path_equity_precision_llm_repo}/preprocessing/epl03_combined output_Training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different scenarios for Development (1 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE FOR DEV SET\n",
    "combined_output_development = pd.DataFrame()\n",
    "for scenario in range(1,5):\n",
    "    results = pd.read_csv(path_equity_precision_llm_folder + '/llm training/Development Scenario '+ str(scenario) +'_results.csv')\n",
    "    merged_df_development = input_development.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "    merged_df_development['source_population_match'] = merged_df_development.apply(lambda row: bool(re.search('(^|\\s)' + str(row['gpt_source_population']),str(row['orig_source_population']))), axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_development,truth='orig_precision_medicine',test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_development,truth='orig_diabetes',test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_development,truth='orig_primary_study',test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'  \n",
    "\n",
    "    t_source_population = pd.crosstab(merged_df_training['source_population_match'], merged_df_training['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum()/t_source_population.sum().sum() \n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study,summary_source_population])\n",
    "    df_summary['Scenario'] = 'Scenario' + str(scenario)\n",
    "    combined_output_development = pd.concat([combined_output_development,df_summary],axis=0,ignore_index=True) \n",
    "\n",
    "combined_output_development.to_csv(path_equity_precision_llm_repo + '/preprocessing/epl03_combined output_Development.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CODE FOR DEV SET\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize an empty DataFrame to store combined results\n",
    "combined_output_development = pd.DataFrame()\n",
    "\n",
    "# Loop through development scenarios\n",
    "for scenario in range(1, 5):\n",
    "    results = pd.read_csv(f\"{path_equity_precision_llm_folder}/llm training/Development Scenario {scenario}_results.csv\")\n",
    "    merged_df_development = input_development.merge(results, left_on='PMID', right_on='pmid', how='left')\n",
    "\n",
    "    # Standardize source population categories\n",
    "    def standardize_population(value):\n",
    "        if pd.isna(value) or value.strip().lower() in [\"unknown\", \"not applicable\", \"n/a\", \"N/A\", \"unk\", \"not specified\", \"Unknown\", \"Not Applicable\", \"Not Specified\"]:\n",
    "            return \"Unknown\"\n",
    "        return value.strip()\n",
    "\n",
    "    merged_df_development['orig_source_population'] = merged_df_development['orig_source_population'].apply(standardize_population)\n",
    "    merged_df_development['gpt_source_population'] = merged_df_development['gpt_source_population'].apply(standardize_population)\n",
    "\n",
    "    # Function for adjusted classification comparison\n",
    "    def adjusted_source_population_match(row):\n",
    "        \"\"\"\n",
    "        Adjusted logic for source population matching:\n",
    "        - If either column is NaN or categorized as \"Unknown\", classify it as 'Unknown'.\n",
    "        - Match is True if GPT's classification contains at least one exact category from the original classification.\n",
    "        \"\"\"\n",
    "        orig_population = row['orig_source_population']\n",
    "        gpt_population = row['gpt_source_population']\n",
    "        \n",
    "        orig_set = set(orig_population.split(', '))\n",
    "        gpt_set = set(gpt_population.split(', '))\n",
    "\n",
    "        # If GPT predicted 'Unknown', it doesn't match any known category.\n",
    "        if gpt_population == 'Unknown':\n",
    "            return orig_population == 'Unknown'  # Only match if both are 'Unknown'\n",
    "\n",
    "        # Match only if GPT contains at least one exact category from the original classification\n",
    "        return any(category in orig_set for category in gpt_set)\n",
    "\n",
    "    # Apply the updated matching logic\n",
    "    merged_df_development['source_population_match'] = merged_df_development.apply(adjusted_source_population_match, axis=1)\n",
    "\n",
    "    # Crosstab summary for precision medicine\n",
    "    summary_precision_medicine = crosstab_summary(merged_df_development, truth='orig_precision_medicine', test='gpt_precision_medicine')\n",
    "    summary_diabetes = crosstab_summary(merged_df_development, truth='orig_diabetes', test='gpt_diabetes')\n",
    "    summary_primary_study = crosstab_summary(merged_df_development, truth='orig_primary_study', test='gpt_primary_study')\n",
    "\n",
    "    summary_precision_medicine['variable'] = 'Precision Medicine'\n",
    "    summary_diabetes['variable'] = 'Diabetes'\n",
    "    summary_primary_study['variable'] = 'Primary Study'\n",
    "\n",
    "    # Generate updated crosstab for source population\n",
    "    t_source_population = pd.crosstab(merged_df_development['source_population_match'], merged_df_development['orig_source_population'])\n",
    "\n",
    "    prop_correct_source_population = t_source_population.loc[True].sum() / t_source_population.sum().sum()\n",
    "    prop_correct_source_population\n",
    "\n",
    "    summary_source_population = pd.DataFrame({'variable': 'Source Population', 'Accuracy': prop_correct_source_population}, index=[0])\n",
    "\n",
    "    df_summary = pd.concat([summary_precision_medicine, summary_diabetes, summary_primary_study, summary_source_population])\n",
    "    df_summary['Scenario'] = f'Scenario{scenario}'\n",
    "    combined_output_development = pd.concat([combined_output_development, df_summary], axis=0, ignore_index=True)\n",
    "\n",
    "# Save the final output\n",
    "combined_output_development.to_csv(f\"{path_equity_precision_llm_repo}/preprocessing/epl03_combined output_Development.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
